{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"MunaqJtU0ylo"},"outputs":[],"source":["# importing necessary libraries\n","import torch\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from torch import nn \n","from torchvision import datasets, transforms, models\n","from torchsampler import ImbalancedDatasetSampler\n","from IPython.display import clear_output\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wwNe7Rf_dwS"},"outputs":[],"source":["!pip install torchsampler\n","clear_output()\n","\n","from torchsampler import ImbalancedDatasetSampler # used to balance the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xyLGIzdV2Z7k"},"outputs":[],"source":["# create a class object to transform each pixel to tensor, applying data augmentation, and finally normalizing each pixel values.\n","transforms = transforms.Compose([transforms.RandomApply([\n","                                      transforms.RandomRotation(10),\n","                                      transforms.RandomHorizontalFlip()],0.7),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a_EWjsvg29Su","outputId":"ff3df3a0-4b5a-42b1-cf16-372dce55d2b2","executionInfo":{"status":"ok","timestamp":1665861224663,"user_tz":-330,"elapsed":22355,"user":{"displayName":"Shalini B S","userId":"01490877147327407709"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# mount colab to drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_XPXzMK6BPZ4"},"outputs":[],"source":["# Loading train and validation datasets with ImageFolder. \n","train_dataset = datasets.ImageFolder('/content/gdrive/MyDrive/object_detection/training_images', transform = transforms)\n","validation_dataset = datasets.ImageFolder('/content/gdrive/MyDrive/object_detection/validation_images', transform = transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B3UxoHQ-1X9J"},"outputs":[],"source":["# create training and validation batches with the given batch size and balance the train dataset using ImbalancedDatasetSampler. \n","batch_size = 32\n","train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler = ImbalancedDatasetSampler(train_dataset), batch_size = batch_size, shuffle = False)\n","validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size = batch_size, shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9POgZoZr1X_g"},"outputs":[],"source":["# to check if the dataset is balanced \n","labels_count = {0:0, 1:0}\n","for image, label in train_dataloader:\n","  for value in label:\n","    if value == 0:\n","      labels_count[0] +=1\n","    else:\n","      labels_count[1] += 1\n","  break\n","  print(labels_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7e2MLcKARPG"},"outputs":[],"source":["# to view a batch of objects and background \n","image, label = next(iter(train_dataloader))\n"," \n","rows = int(image.shape[0]/8)\n","columns = int(image.shape[0]/rows)\n","plt.figure(figsize = (12, 8))\n","\n","for i in range(image.shape[0]):\n","  plt.subplot(rows, columns, i + 1)\n","  plt.imshow(image[i].squeeze().permute(1, 2, 0))\n","  plt.title(label[i])\n","  plt.axis('off')\n","  plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDt2H8-TBFIj","outputId":"c10a642a-3424-4abb-865a-3512230f9317","executionInfo":{"status":"ok","timestamp":1665861327824,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shalini B S","userId":"01490877147327407709"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# defining the device \n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPjbzv5fFjEv"},"outputs":[],"source":["# defining resene18 model\n","model = models.resnet18(pretrained = True)\n","\n","for param in model.parameters():\n","  param.requires_grad = False\n","\n","# replacing the classifier layer of resnet model with our classification layers. \n","classifier = nn.Sequential(nn.Linear(512, 512), \n","                     nn.ReLU(), \n","                     nn.Dropout(0.2),\n","                     nn.Linear(512, 256), \n","                     nn.ReLU(), \n","                     nn.Dropout(0.2), \n","                     nn.Linear(256, 2)\n","                     )\n","\n","model.fc = classifier\n","model.to(device)\n","\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CkKtmPnxEyQr"},"outputs":[],"source":["# defining loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","criterion.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kN-rTCHGHNYw"},"outputs":[],"source":["def train_loop(train_dataloader, model, criterion, optimizer):\n","  model.train()\n","  size = len(train_dataset)\n","  for batch, (image, label) in enumerate(train_dataloader):\n","    image = image.to(device)\n","    label = label.to(device)\n","\n","    logits = model(image)\n","    optimizer.zero_grad()\n","    loss = criterion(logits, label)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    loss += loss.item()\n","    if batch % 20 == 0:\n","      loss, current = loss.item(), batch * len(image)\n","      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FKnAul62jIpD"},"outputs":[],"source":["def validation_loop(dataloader, model, criterion, optimizer):\n","  model.eval()\n","  validation_loss = 0\n","  correct = 0\n","  min_validation_loss = np.inf\n","  \n","  with torch.no_grad():\n","    for images, labels in dataloader:\n","      images = images.to(device)\n","      labels = labels.to(device)\n","      pred = model(images)\n","      # print(pred)\n","      loss = criterion(pred, labels)\n","      # loss = loss.to(device)\n","      validation_loss += loss.item()\n","      correct += (pred.argmax(1) == labels).type(torch.float).sum().item()\n","  \n","  validation_accuracy = validation_loss/len(dataloader)\n","  correct = correct/len(dataloader.dataset)\n","  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {loss:>8f} \\n\")\n","  if min_validation > validation_loss:\n","    print(f'Validation Loss Decreased({min_validation_loss:.6f}--->{validation_loss:.6f}) \\t Saving The Model')\n","    min_validation_loss = validation_loss\n","    torch.save(model.state_dict(), '/content/gdrive/MyDrive/model1.pt')\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"reG02hAEI31-","outputId":"b9b4e2d8-ba60-4a70-b9d2-0e1e9e23e417","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665867625801,"user_tz":-330,"elapsed":6292665,"user":{"displayName":"Shalini B S","userId":"01490877147327407709"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 1:\n","loss: 1.386538  [    0/11309]\n","loss: 1.427075  [  640/11309]\n","loss: 1.403570  [ 1280/11309]\n","loss: 1.376046  [ 1920/11309]\n","loss: 1.372760  [ 2560/11309]\n","loss: 1.427269  [ 3200/11309]\n","loss: 1.311236  [ 3840/11309]\n","loss: 1.343429  [ 4480/11309]\n","loss: 1.315744  [ 5120/11309]\n","loss: 1.321029  [ 5760/11309]\n","loss: 1.312622  [ 6400/11309]\n","loss: 1.293927  [ 7040/11309]\n","loss: 1.308969  [ 7680/11309]\n","loss: 1.224994  [ 8320/11309]\n","loss: 1.327211  [ 8960/11309]\n","loss: 1.276870  [ 9600/11309]\n","loss: 1.287382  [10240/11309]\n","loss: 1.260913  [10880/11309]\n","Test Error: \n"," Accuracy: 73.3%, Avg loss: 0.672634 \n","\n","Validation Loss Decreased(inf--->39.036505) \t Saving The Model\n","epoch 2:\n","loss: 1.253874  [    0/11309]\n","loss: 1.213523  [  640/11309]\n","loss: 1.221172  [ 1280/11309]\n","loss: 1.191337  [ 1920/11309]\n","loss: 1.182187  [ 2560/11309]\n","loss: 1.112442  [ 3200/11309]\n","loss: 1.306212  [ 3840/11309]\n","loss: 1.207225  [ 4480/11309]\n","loss: 1.054762  [ 5120/11309]\n","loss: 1.164393  [ 5760/11309]\n","loss: 1.037158  [ 6400/11309]\n","loss: 1.126321  [ 7040/11309]\n","loss: 1.009612  [ 7680/11309]\n","loss: 1.109084  [ 8320/11309]\n","loss: 0.963471  [ 8960/11309]\n","loss: 0.999138  [ 9600/11309]\n","loss: 0.965106  [10240/11309]\n","loss: 1.096126  [10880/11309]\n","Test Error: \n"," Accuracy: 80.7%, Avg loss: 0.463629 \n","\n","Validation Loss Decreased(inf--->32.452402) \t Saving The Model\n","epoch 3:\n","loss: 0.976577  [    0/11309]\n","loss: 0.959844  [  640/11309]\n","loss: 1.025360  [ 1280/11309]\n","loss: 0.940020  [ 1920/11309]\n","loss: 1.005872  [ 2560/11309]\n","loss: 0.875095  [ 3200/11309]\n","loss: 0.999180  [ 3840/11309]\n","loss: 0.950817  [ 4480/11309]\n","loss: 1.047453  [ 5120/11309]\n","loss: 0.820399  [ 5760/11309]\n","loss: 0.990015  [ 6400/11309]\n","loss: 1.057464  [ 7040/11309]\n","loss: 0.892681  [ 7680/11309]\n","loss: 1.081162  [ 8320/11309]\n","loss: 1.042735  [ 8960/11309]\n","loss: 1.168758  [ 9600/11309]\n","loss: 0.780480  [10240/11309]\n","loss: 0.929438  [10880/11309]\n","Test Error: \n"," Accuracy: 85.1%, Avg loss: 0.357669 \n","\n","Validation Loss Decreased(inf--->26.505603) \t Saving The Model\n","epoch 4:\n","loss: 0.826919  [    0/11309]\n","loss: 0.832365  [  640/11309]\n","loss: 0.930079  [ 1280/11309]\n","loss: 0.967643  [ 1920/11309]\n","loss: 0.978035  [ 2560/11309]\n","loss: 0.922417  [ 3200/11309]\n","loss: 0.712516  [ 3840/11309]\n","loss: 0.682486  [ 4480/11309]\n","loss: 0.764887  [ 5120/11309]\n","loss: 0.794936  [ 5760/11309]\n","loss: 0.765877  [ 6400/11309]\n","loss: 0.769267  [ 7040/11309]\n","loss: 0.821001  [ 7680/11309]\n","loss: 0.956881  [ 8320/11309]\n","loss: 0.713203  [ 8960/11309]\n","loss: 1.134113  [ 9600/11309]\n","loss: 0.988447  [10240/11309]\n","loss: 1.022722  [10880/11309]\n","Test Error: \n"," Accuracy: 88.4%, Avg loss: 0.338753 \n","\n","Validation Loss Decreased(inf--->21.285085) \t Saving The Model\n","epoch 5:\n","loss: 0.883347  [    0/11309]\n","loss: 0.774685  [  640/11309]\n","loss: 0.721228  [ 1280/11309]\n","loss: 0.722418  [ 1920/11309]\n","loss: 0.908205  [ 2560/11309]\n","loss: 0.693727  [ 3200/11309]\n","loss: 0.557369  [ 3840/11309]\n","loss: 0.424750  [ 4480/11309]\n","loss: 1.092796  [ 5120/11309]\n","loss: 0.738607  [ 5760/11309]\n","loss: 0.518290  [ 6400/11309]\n","loss: 0.564508  [ 7040/11309]\n","loss: 0.770572  [ 7680/11309]\n","loss: 0.698150  [ 8320/11309]\n","loss: 0.617892  [ 8960/11309]\n","loss: 0.974337  [ 9600/11309]\n","loss: 0.783600  [10240/11309]\n","loss: 0.792299  [10880/11309]\n","Test Error: \n"," Accuracy: 87.7%, Avg loss: 0.310945 \n","\n","Validation Loss Decreased(inf--->20.414270) \t Saving The Model\n","epoch 6:\n","loss: 0.701286  [    0/11309]\n","loss: 0.632219  [  640/11309]\n","loss: 0.806144  [ 1280/11309]\n","loss: 0.816011  [ 1920/11309]\n","loss: 0.825495  [ 2560/11309]\n","loss: 0.631213  [ 3200/11309]\n","loss: 0.735616  [ 3840/11309]\n","loss: 0.649144  [ 4480/11309]\n","loss: 0.887074  [ 5120/11309]\n","loss: 0.703665  [ 5760/11309]\n","loss: 0.905532  [ 6400/11309]\n","loss: 0.652248  [ 7040/11309]\n","loss: 0.841363  [ 7680/11309]\n","loss: 0.684809  [ 8320/11309]\n","loss: 0.923948  [ 8960/11309]\n","loss: 0.639233  [ 9600/11309]\n","loss: 0.914329  [10240/11309]\n","loss: 0.535240  [10880/11309]\n","Test Error: \n"," Accuracy: 88.2%, Avg loss: 0.359670 \n","\n","Validation Loss Decreased(inf--->19.475248) \t Saving The Model\n","epoch 7:\n","loss: 0.501886  [    0/11309]\n","loss: 0.741329  [  640/11309]\n","loss: 0.461631  [ 1280/11309]\n","loss: 0.834807  [ 1920/11309]\n","loss: 0.919816  [ 2560/11309]\n","loss: 0.705305  [ 3200/11309]\n","loss: 0.504962  [ 3840/11309]\n","loss: 0.727238  [ 4480/11309]\n","loss: 0.687984  [ 5120/11309]\n","loss: 0.818954  [ 5760/11309]\n","loss: 0.524297  [ 6400/11309]\n","loss: 0.595083  [ 7040/11309]\n","loss: 0.754557  [ 7680/11309]\n","loss: 0.981602  [ 8320/11309]\n","loss: 0.756076  [ 8960/11309]\n","loss: 0.903991  [ 9600/11309]\n","loss: 0.641383  [10240/11309]\n","loss: 0.859464  [10880/11309]\n","Test Error: \n"," Accuracy: 88.4%, Avg loss: 0.206946 \n","\n","Validation Loss Decreased(inf--->20.003672) \t Saving The Model\n","epoch 8:\n","loss: 0.496681  [    0/11309]\n","loss: 0.953600  [  640/11309]\n","loss: 0.955673  [ 1280/11309]\n","loss: 0.712472  [ 1920/11309]\n","loss: 0.675719  [ 2560/11309]\n","loss: 0.690126  [ 3200/11309]\n","loss: 0.527422  [ 3840/11309]\n","loss: 0.376202  [ 4480/11309]\n","loss: 0.482788  [ 5120/11309]\n","loss: 1.130797  [ 5760/11309]\n","loss: 0.819957  [ 6400/11309]\n","loss: 0.575251  [ 7040/11309]\n","loss: 0.779907  [ 7680/11309]\n","loss: 0.520861  [ 8320/11309]\n","loss: 0.652296  [ 8960/11309]\n","loss: 0.920693  [ 9600/11309]\n","loss: 0.663557  [10240/11309]\n","loss: 0.311625  [10880/11309]\n","Test Error: \n"," Accuracy: 89.4%, Avg loss: 0.319732 \n","\n","Validation Loss Decreased(inf--->18.177301) \t Saving The Model\n","epoch 9:\n","loss: 0.931597  [    0/11309]\n","loss: 0.782267  [  640/11309]\n","loss: 0.685137  [ 1280/11309]\n","loss: 0.788038  [ 1920/11309]\n","loss: 0.745867  [ 2560/11309]\n","loss: 0.833842  [ 3200/11309]\n","loss: 0.610002  [ 3840/11309]\n","loss: 0.826617  [ 4480/11309]\n","loss: 0.386949  [ 5120/11309]\n","loss: 0.652540  [ 5760/11309]\n","loss: 0.494246  [ 6400/11309]\n","loss: 1.147256  [ 7040/11309]\n","loss: 0.690004  [ 7680/11309]\n","loss: 0.530516  [ 8320/11309]\n","loss: 0.564991  [ 8960/11309]\n","loss: 0.566458  [ 9600/11309]\n","loss: 0.445714  [10240/11309]\n","loss: 0.488623  [10880/11309]\n","Test Error: \n"," Accuracy: 89.5%, Avg loss: 0.195819 \n","\n","Validation Loss Decreased(inf--->17.253229) \t Saving The Model\n","epoch 10:\n","loss: 0.936735  [    0/11309]\n","loss: 0.455642  [  640/11309]\n","loss: 0.790744  [ 1280/11309]\n","loss: 0.609436  [ 1920/11309]\n","loss: 0.450483  [ 2560/11309]\n","loss: 0.494039  [ 3200/11309]\n","loss: 0.571545  [ 3840/11309]\n","loss: 0.360706  [ 4480/11309]\n","loss: 0.333610  [ 5120/11309]\n","loss: 0.996629  [ 5760/11309]\n","loss: 0.722178  [ 6400/11309]\n","loss: 0.705921  [ 7040/11309]\n","loss: 0.559178  [ 7680/11309]\n","loss: 0.646931  [ 8320/11309]\n","loss: 0.801151  [ 8960/11309]\n","loss: 0.401076  [ 9600/11309]\n","loss: 0.611854  [10240/11309]\n","loss: 0.709085  [10880/11309]\n","Test Error: \n"," Accuracy: 90.7%, Avg loss: 0.426672 \n","\n","Validation Loss Decreased(inf--->16.115317) \t Saving The Model\n"]}],"source":["epoch = 10\n","for i in range(epoch):\n","  print(f'epoch {i+1}:' )\n","  train_loop(train_dataloader, model, criterion, optimizer)\n","  validation_loop(validation_dataloader, model, criterion, optimizer)\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyPd5lvLbu2sGVie+WHeJhLx"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}